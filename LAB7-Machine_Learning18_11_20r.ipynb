{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning18.11.20r.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz-hz9TuY3AT",
        "outputId": "a334c6ba-a800-40f7-c533-bf2f1e81a049"
      },
      "source": [
        "#Celem tego laboratorium było zapoznanie się z uczeniem maszynowym\n",
        "#Pandy to podstawowe narzędzie, którego naukowcy używają do eksploracji i manipulowania danymi. Większość ludzi skraca pandy w swoim kodzie jako pd.\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "76rD2kqHaoea",
        "outputId": "26499b30-40ea-4e63-b542-bbbad48039eb"
      },
      "source": [
        "### Zbieranie danych dotyczących cen domów w Melbourne\n",
        "import pandas as pd\n",
        "#Przykładowe dane (Melbourne) znajdują się w ścieżce pliku ../input/melbourne-housing-snapshot/melb_data.csv, a ich dodanie zostało przedstawione poniżej.\n",
        "melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n",
        "melbourne_data = pd.read_csv(melbourne_file_path) \n",
        "melbourne_data.columns\n",
        "\n",
        "# Dropna pomija brakujące wartości z plików.\n",
        "melbourne_data = melbourne_data.dropna(axis=0)\n",
        "### Kolumny, które zostały wprowadzone do programu są traktowane jako funkcje i służą do prognozowania. W tym przypadku byłyby to kolumny do określenia ceny domu.\n",
        "## Wybór wielu funkcji, podając listę nazw kolumn w nawiasach. Każda pozycja na tej liście powinna być ciągiem znaków (w cudzysłowach).\n",
        "y = melbourne_data.Price\n",
        "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
        "## Te dane zostały nazwane X\n",
        "X = melbourne_data[melbourne_features]\n",
        "#Dane, których będziemy używać do przewidywania cen domów za pomocą metody opisywania i metody ceny podstawowej.\n",
        "X.describe()\n",
        "X.head()\n",
        "\n",
        "### BUDOWANIE MODELU DRZEWA DECYZYJNEGO\n",
        "###Do tworzenia modeli wykorzystano bibliotekę scikit-learning.\n",
        "### Podczas kodowania ta biblioteka jest zapisywana jako sklearn. Scikit-learn jest z łatwością najpopularniejszą biblioteką do modelowania typów danych zwykle przechowywanych w DataFrames.\n",
        "\n",
        "### Poniżej przedsawiłem kod budujący drzewo decyzyjne.\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Define model. Specify a number for random_state to ensure same results each run\n",
        "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
        "\n",
        "# Fit model\n",
        "melbourne_model.fit(X, y)\n",
        "##Wiele modeli uczenia maszynowego dopuszcza pewną przypadkowość w uczeniu modeli.\n",
        "## Określenie liczby dla random_state zapewnia takie same wyniki w każdym przebiegu.\n",
        "\n",
        "#Mamy teraz dopasowany model, którego możemy użyć do prognozowania.\n",
        "\n",
        "#W praktyce trzeba będzie przewidywać nowe domy wchodzące na rynek, a nie domy, dla których mamy już ceny.\n",
        "## Ale zrobimy prognozy dla pierwszych kilku wierszy danych uczących, aby zobaczyć, jak działa funkcja przewidywania.\n",
        "\n",
        "print(\"Making predictions for the following 5 houses:\")\n",
        "print(X.head())\n",
        "print(\"The predictions are\")\n",
        "print(melbourne_model.predict(X.head()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fff19af11d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmelbourne_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/melbourne-housing-snapshot/melb_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmelbourne_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelbourne_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmelbourne_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/melbourne-housing-snapshot/melb_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "IusnzFMbdhBK",
        "outputId": "8388926b-7db0-4d2f-fab1-c8c96f0df665"
      },
      "source": [
        "## WALIDACJA MODELU\n",
        "#Co to jest walidacja modelu\n",
        "\n",
        "## W większości (choć nie we wszystkich) zastosowaniach odpowiednią miarą jakości modelu jest dokładność predykcyjna. Innymi słowy, czy przewidywania modelu będą bliskie temu, co faktycznie się dzieje.\n",
        "# Wiele osób popełnia ogromny błąd podczas pomiaru dokładności predykcyjnej. Tworzą prognozy na podstawie danych szkoleniowych i porównują te prognozy z wartościami docelowymi w danych szkoleniowych. Za chwilę zobaczysz problem z tym podejściem i jak go rozwiązać, ale zastanówmy się najpierw, jak to zrobimy.\n",
        "#Najpierw trzeba podsumować jakość modelu w zrozumiały sposób. Jeśli zostaną porównane przewidywane i rzeczywiste wartości domów dla 10 000 domów, prawdopodobnie zostanie znalezione połączenie dobrych i złych prognoz. Przeglądanie listy 10 000 przewidywanych i rzeczywistych wartości byłoby bezcelowe. \n",
        "#Trzeba podsumować to w jednej metryce.\n",
        "#Istnieje wiele metryk służących do podsumowania jakości modelu, ale zaczniemy od metryki o nazwie Średni błąd bezwzględny (zwanej również MAE). Dane zostaną podzielone, zaczynając od ostatniego słowa, błędu.\n",
        "\n",
        "#Gdy mamy już model, oto jak obliczyć średni błąd bezwzględny:\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "predicted_home_prices = melbourne_model.predict(X)\n",
        "mean_absolute_error(y, predicted_home_prices)\n",
        "\n",
        "#Powyższą miarę można nazwać wynikiem „w próbce”. Została wykorzystana jedna „próbka” domów zarówno do zbudowania modelu, jak i do jego oceny. Oto dlaczego to jest złe.\n",
        "#Zadaniem tego modelu jest znalezienie wzorców, które przewidują ceny domów, więc zobaczy ten wzór i zawsze będzie przewidywał wysokie ceny domów z zielonymi drzwiami.\n",
        "#Ponieważ ten wzorzec został wyprowadzony z danych uczących, model będzie wyglądał dokładnie w danych uczących.\n",
        "#Ale jeśli ten wzorzec nie zachowuje się, gdy model widzi nowe dane, model byłby bardzo niedokładny w praktyce.\n",
        "#Ponieważ praktyczna wartość modeli wynika z prognozowania nowych danych, mierzymy wydajność na danych, które nie zostały użyte do zbudowania modelu.\n",
        "# Najprostszym sposobem na to jest wykluczenie niektórych danych z procesu budowania modelu, a następnie użycie ich do przetestowania dokładności modelu na danych, których wcześniej nie widział. \n",
        "#Te dane nazywane są danymi walidacyjnymi.\n",
        "\n",
        "#Podział danych na dane treningowe i walidacyjne, zarówno dla funkcji, jak i celu\n",
        "#Podział jest oparty na generatorze liczb losowych. Podanie wartości liczbowej do\n",
        "# argument random_state gwarantuje, że za każdym razem otrzymamy taki sam podział\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Podział danych na dane treningowe i walidacyjne, zarówno dla funkcji, jak i celu\n",
        "#Podział jest oparty na generatorze liczb losowych. Podanie wartości liczbowej do\n",
        "# argument random_state gwarantuje, że za każdym razem otrzymamy taki sam podział\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
        "# Definiowanie modelu\n",
        "melbourne_model = DecisionTreeRegressor()\n",
        "# Dopasowanie modelu\n",
        "melbourne_model.fit(train_X, train_y)\n",
        "\n",
        "# Przewidywane ceny na danych walidacyjnych\n",
        "val_predictions = melbourne_model.predict(val_X)\n",
        "print(mean_absolute_error(val_y, val_predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3f836feb7329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredicted_home_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelbourne_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_home_prices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'melbourne_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "81ml6YaXeORH",
        "outputId": "ce72b560-405e-4d18-8e2f-72be2ff4bfa1"
      },
      "source": [
        "##Kiedy dzielimy domy na wiele liści, mamy również mniej domów na każdym liściu. \n",
        "##Liście z bardzo małą liczbą domów będą przewidywać, które są dość zbliżone do rzeczywistych wartości tych domów,\n",
        "## ale mogą stanowić bardzo niewiarygodne prognozy dla nowych danych (ponieważ każda prognoza opiera się tylko na kilku domach).\n",
        "\n",
        "#Jest to zjawisko zwane overfittingiem, w którym model prawie idealnie pasuje do danych uczących, ale źle radzi sobie z walidacją i innymi nowymi danymi.\n",
        "# Z drugiej strony, jeśli sprawimy, że nasze drzewo będzie bardzo płytkie, nie podzieli ono domów na bardzo odrębne grupy.\n",
        "\n",
        "#Istnieje kilka alternatyw kontrolowania głębokości drzewa, a wiele z nich pozwala, aby niektóre trasy w drzewie miały większą głębokość niż inne trasy.\n",
        "#Ale argument max_leaf_nodes zapewnia bardzo rozsądny sposób kontrolowania nadmiernego i niedostatecznego dopasowania.\n",
        "#Im więcej liści pozwolimy modelowi wykonać, tym bardziej przechodzimy od obszaru niedopasowania na powyższym wykresie do obszaru nadmiernego dopasowania.\n",
        "\n",
        "#Możemy użyć funkcji narzędzia, aby pomóc porównać wyniki MAE z różnych wartości dla max_leaf_nodes:\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
        "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
        "    model.fit(train_X, train_y)\n",
        "    preds_val = model.predict(val_X)\n",
        "    mae = mean_absolute_error(val_y, preds_val)\n",
        "    return(mae)\n",
        "\n",
        "\n",
        "#Dane są ładowane do train_X, val_X, train_y i val_y.\n",
        "#Można użyć pętli for do porównania dokładności modeli zbudowanych z różnymi wartościami max_leaf_nodes.\n",
        "\n",
        "# porównanie MAE z różnymi wartościami max_leaf_nodes\n",
        "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
        "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
        "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n",
        "\n",
        "#Oto wnioski: modele mogą cierpieć na:\n",
        "#-Overfitting: wychwytywanie fałszywych wzorców, które nie będą się powtarzać w przyszłości, co prowadzi do mniej dokładnych prognoz.\n",
        "#-Niedopasowanie: brak możliwości uchwycenia odpowiednich wzorców, co ponownie prowadzi do mniej dokładnych prognoz.\n",
        "#Używamy danych walidacyjnych, które nie są używane w uczeniu modelu, do pomiaru dokładności modelu kandydata. Dzięki temu możemy wypróbować wiele modeli kandydatów i zachować najlepszy.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-011f5b23b54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# compare MAE with differing values of max_leaf_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmy_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_AFBxUIfBxc"
      },
      "source": [
        "### LOSOWY LAS\n",
        "\n",
        "#Losowy las wykorzystuje wiele drzew i dokonuje przewidywań, uśredniając przewidywania każdego drzewa składowego.\n",
        "#Generalnie ma znacznie lepszą dokładność predykcyjną niż pojedyncze drzewo decyzyjne i działa dobrze z parametrami domyślnymi.\n",
        "#Jeśli będzie kontynuowane modelowanie, można nauczyć więcej modeli z jeszcze lepszą wydajnością, ale wiele z nich jest wrażliwych na uzyskanie odpowiednich parametrów.\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "forest_model = RandomForestRegressor(random_state=1)\n",
        "forest_model.fit(train_X, train_y)\n",
        "melb_preds = forest_model.predict(val_X)\n",
        "print(mean_absolute_error(val_y, melb_preds))\n",
        "\n",
        "##Istnieją parametry, które pozwalają zmienić wydajność losowego lasu, podobnie jak zmieniana była maksymalną głębokość pojedynczego drzewa decyzyjnego.\n",
        "##Ale jedną z najlepszych cech modeli Random Forest jest to, że generalnie działają one rozsądnie nawet bez tego tuningu.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}